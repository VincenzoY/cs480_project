{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":81655,"databundleVersionId":8915386,"sourceType":"competition"},{"sourceId":9088140,"sourceType":"datasetVersion","datasetId":5483815},{"sourceId":9088670,"sourceType":"datasetVersion","datasetId":5484195},{"sourceId":88237,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":74090,"modelId":98897},{"sourceId":88383,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":74181,"modelId":98957}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport torchvision.transforms\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom PIL import Image\nfrom enum import Enum\n\nclass DataSource(Enum):\n    TRAIN = 1\n    TEST = 2\n\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n])\n    \ndef fetch_image_as_tensor(id: int, image_type: DataSource):\n    image_folder = \"train_images\" if image_type == DataSource.TRAIN else \"test_images\"\n    \n    return transform(Image.open(f\"/kaggle/input/cs-480-2024-spring/data/{image_folder}/{id}.jpeg\"))\n\ndef reject_outliers(data, m=3):\n    results = np.log10(data[:, 164:])\n\n    return data[np.all(abs(results - np.mean(results, axis=0)) < m * np.std(results, axis=0), axis=1)]\n\ndef model_output_to_traits(output, train_min, train_max):\n    return 10 ** (output * (np.log10(train_max) - np.log10(train_min)) + np.log10(train_min))\n\nclass TrainDataset(Dataset):\n    def __init__(self, data, train_min, train_max):\n        self.data = data\n        self.log_train_min = np.log10(train_min)\n        self.log_train_max = np.log10(train_max)\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, row_index):\n        row = self.data[row_index]\n        index = int(row[0])\n        image = fetch_image_as_tensor(index, DataSource.TRAIN)\n        aux_data = torch.tensor(row[1:164]).float()\n        \n        result = torch.tensor((np.log10(row[164:]) - self.log_train_min) / (self.log_train_max - self.log_train_min)).float()\n        \n        return image, aux_data, result\n    \nnp.random.seed(0)\n    \nbatch_size = 128\n\nknown_values = pd.read_csv('/kaggle/input/cs-480-2024-spring/data/train.csv').values\nfiltered_known_values = reject_outliers(known_values)\n\nindices = np.random.permutation(filtered_known_values.shape[0])\nsplit_index = int(0.8 * len(filtered_known_values))\ntrain_idx, validation_idx = indices[:split_index], indices[split_index:]\ntrain_subset, validation_subset = filtered_known_values[train_idx,:], filtered_known_values[validation_idx,:]\n\nTRAIN_MIN = np.min(train_subset[:, 164:], axis=0)\nTRAIN_MAX = np.max(train_subset[:, 164:], axis=0)\n\ntrain_data_loader = DataLoader(TrainDataset(train_subset, TRAIN_MIN, TRAIN_MAX), batch_size=batch_size)\nvalidation_data_loader = DataLoader(TrainDataset(validation_subset, TRAIN_MIN, TRAIN_MAX), batch_size=batch_size)\n\nfor a, b, c in train_data_loader:\n    print(f\"Shape of a: {a.shape}\")\n    print(f\"Shape of b: {b.shape}\")\n    print(f\"Shape of c: {c.shape}\")\n    break\n\n#print(train_tensor[0][0:5])\n#print(train_tensor[1])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-04T08:05:43.652810Z","iopub.execute_input":"2024-08-04T08:05:43.653557Z","iopub.status.idle":"2024-08-04T08:05:45.115295Z","shell.execute_reply.started":"2024-08-04T08:05:43.653528Z","shell.execute_reply":"2024-08-04T08:05:45.114298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision.models as models\n\ndevice = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.cnn = models.resnet152()\n        \n        self.aux_linear_relu_stack = nn.Sequential(\n            nn.Linear(163, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n        )\n        \n        self.combined_linear_relu_stack = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(self.cnn.fc.out_features + 256, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, 6),\n        )\n        \n    def forward(self, image, aux_data):\n        x1 = self.cnn(image)\n        x2 = self.aux_linear_relu_stack(aux_data)\n        \n        x = torch.cat((x1, x2), dim=1)\n        x = self.combined_linear_relu_stack(x)\n        return x\n        \nmodel = NeuralNetwork().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T07:48:57.935625Z","iopub.execute_input":"2024-08-04T07:48:57.936005Z","iopub.status.idle":"2024-08-04T07:49:00.845366Z","shell.execute_reply.started":"2024-08-04T07:48:57.935976Z","shell.execute_reply":"2024-08-04T07:49:00.844481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters())\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (x, aux_data, y) in enumerate(dataloader):\n        x, aux_data, y = x.to(device), aux_data.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(x, aux_data)\n        loss = loss_fn(pred, y)\n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), (batch + 1) * len(x)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n            \ndef validate(dataloader, model, loss_fn):\n    \n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss = 0\n\n    with torch.no_grad():\n        for x, aux_data, y in dataloader:\n            num_batches += 1\n            x, aux_data, y = x.to(device), aux_data.to(device), y.to(device)\n            pred = model(x, aux_data)\n            \n            test_loss += loss_fn(pred, y).item()\n\n    test_loss /= num_batches\n\n    print(f\"Avg loss: {test_loss:>8f} \\n\")\n    \n    return test_loss\n    \ndef test():\n    test_values = pd.read_csv('/kaggle/input/cs-480-2024-spring/data/test.csv').values\n\n    with torch.no_grad():\n        final_predictions = np.array([])\n        for row in test_values:\n            index = int(row[0])\n            image = fetch_image_as_tensor(index, DataSource.TEST).unsqueeze(0)\n            aux_data = torch.tensor(row[1:164]).float().unsqueeze(0)\n\n            image, aux_data = image.to(device), aux_data.to(device)\n            pred = model(image, aux_data)\n            pred_np = model_output_to_traits(pred.cpu().numpy()[0], TRAIN_MIN, TRAIN_MAX)\n\n            if final_predictions.any():\n                final_predictions = np.append(\n                    final_predictions, \n                    [np.concatenate(([index], pred_np))],\n                    axis=0\n                )\n            else:\n                final_predictions = np.array([np.concatenate(([index], pred_np))])\n\n        df = pd.DataFrame(final_predictions)\n\n        df.to_csv(\"predictions.csv\",index=False)  ","metadata":{"execution":{"iopub.status.busy":"2024-08-04T07:49:05.541387Z","iopub.execute_input":"2024-08-04T07:49:05.542314Z","iopub.status.idle":"2024-08-04T07:49:05.557186Z","shell.execute_reply.started":"2024-08-04T07:49:05.542276Z","shell.execute_reply":"2024-08-04T07:49:05.555976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#20\n\nepochs = 40\nmin_epochs = 10\n\nmin_val_loss = float('inf')\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_data_loader, model, loss_fn, optimizer)\n    val_loss = validate(validation_data_loader, model, loss_fn)\n    \n    if val_loss < min_val_loss:\n        min_val_loss = val_loss\n        \n        if epochs >= min_epochs:\n            test()\n            \nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T07:49:14.568104Z","iopub.execute_input":"2024-08-04T07:49:14.568496Z","iopub.status.idle":"2024-08-04T08:05:27.017488Z","shell.execute_reply.started":"2024-08-04T07:49:14.568460Z","shell.execute_reply":"2024-08-04T08:05:27.016466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    for x, aux_data, y in validation_data_loader:\n        x, aux_data, y = x.to(device), aux_data.to(device), y.to(device)\n        pred = model(x, aux_data)\n        \n        print(model_output_to_traits(pred.cpu(), TRAIN_MIN, TRAIN_MAX)[0:4])\n        print(model_output_to_traits(y.cpu(), TRAIN_MIN, TRAIN_MAX)[0:4])\n        break","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:11:10.936736Z","iopub.execute_input":"2024-08-04T08:11:10.937123Z","iopub.status.idle":"2024-08-04T08:11:11.474779Z","shell.execute_reply.started":"2024-08-04T08:11:10.937097Z","shell.execute_reply":"2024-08-04T08:11:11.473713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model.pth\")\nprint(\"Saved PyTorch Model State to model.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T19:26:07.151025Z","iopub.execute_input":"2024-08-03T19:26:07.151781Z","iopub.status.idle":"2024-08-03T19:26:07.931871Z","shell.execute_reply.started":"2024-08-03T19:26:07.151751Z","shell.execute_reply":"2024-08-03T19:26:07.930774Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
